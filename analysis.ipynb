{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing relevant packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to the JSON file\n",
    "filepath = \"data/data.json\"\n",
    "\n",
    "# Open the JSON file and load its contents into a Python dictionary\n",
    "with open(filepath, \"r\") as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want the keys to be integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {int(key): value for key, value in data.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have to handle the fact that some of the scenarios were renamed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key mapping for normalization\n",
    "key_mapping = {\n",
    "    \"Reference\": \"Current Policies\",\n",
    "    \"New Policies\": \"Stated Policies\",\n",
    "}\n",
    "\n",
    "relevant_keys = [\"Current Policies\", \"Stated Policies\", \"Announced Pledges\"]\n",
    "\n",
    "\n",
    "# Step 0: Normalize keys across all values\n",
    "def normalize_keys(data_dict):\n",
    "    for content in data_dict.values():\n",
    "        values = content.get(\"values\", {})\n",
    "        normalized_values = {}\n",
    "        for key, value in values.items():\n",
    "            normalized_key = key_mapping.get(key, key)  # Map key if in key_mapping\n",
    "            if normalized_key in normalized_values:\n",
    "                print(\n",
    "                    f\"Warning: Duplicate normalized key '{normalized_key}'. Overwriting previous entry.\"\n",
    "                )\n",
    "            normalized_values[normalized_key] = value\n",
    "        content[\"values\"] = normalized_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_keys(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to be able to interpolate the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_splines(data_dict):\n",
    "    for _, content in data_dict.items():\n",
    "        # Extract years and values\n",
    "        year_values = content[\"year\"]\n",
    "        value_dict = content[\"values\"]\n",
    "\n",
    "        # Create a new \"splines\" dictionary\n",
    "        splines = {}\n",
    "        for key, values in value_dict.items():\n",
    "            # Handle null values by filtering them out\n",
    "            valid_data = [\n",
    "                (yr, val) for yr, val in zip(year_values, values) if val is not None\n",
    "            ]\n",
    "            if len(valid_data) >= 2:  # Ensure there are enough points to interpolate\n",
    "                valid_years, valid_values = zip(*valid_data)\n",
    "                spline = interp1d(\n",
    "                    valid_years, valid_values, kind=\"cubic\", fill_value=\"extrapolate\"\n",
    "                )\n",
    "                splines[key] = spline  # Store the spline function\n",
    "            else:\n",
    "                splines[key] = None  # Not enough data points or missing values\n",
    "\n",
    "        # Add \"splines\" to the content\n",
    "        content[\"splines\"] = splines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_splines(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I need a method of extracting the predictions for the same scenario over the years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_values(data_dict, unique_keys, year_test):\n",
    "    values = {key: [] for key in unique_keys}\n",
    "    years = []  # To keep track of x-axis years\n",
    "\n",
    "    for year, content in data_dict.items():\n",
    "        years.append(year)\n",
    "        splines = content.get(\"splines\", {})\n",
    "        for key in unique_keys:\n",
    "            if key in splines and splines[key] is not None:  # Valid spline exists\n",
    "                values[key].append(splines[key](year_test).item())\n",
    "            else:\n",
    "                values[key].append(None)  # Append None if no valid spline\n",
    "\n",
    "    return years, values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_year = 2019\n",
    "\n",
    "years, values_2019 = obtain_values(data, relevant_keys, reference_year)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
